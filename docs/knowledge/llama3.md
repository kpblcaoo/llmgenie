# Llama 3: особенности, best practices и ограничения

## Описание
- Llama 3 — open-source LLM от Meta, доступна для локального и облачного inference.
- Поддерживается Ollama, LM Studio, HuggingFace и др.

## Особенности
- Высокое качество генерации, поддержка больших контекстов.
- Требует значительных ресурсов для inference.

## Best practices
- Использовать актуальные веса и tokenizer.
- Проверять совместимость с платформой.
- Для production — тестировать latency и memory usage.

## Типовые ошибки
- Несовместимость версий весов и движка.
- Недостаточно памяти для inference.

## Ссылки
- https://github.com/meta-llama/llama3 